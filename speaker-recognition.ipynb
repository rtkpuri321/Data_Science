{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ec3cdd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-16T06:30:53.863386Z",
     "iopub.status.busy": "2022-03-16T06:30:53.861841Z",
     "iopub.status.idle": "2022-03-16T06:30:58.437774Z",
     "shell.execute_reply": "2022-03-16T06:30:58.438254Z",
     "shell.execute_reply.started": "2022-03-16T04:53:48.868167Z"
    },
    "papermill": {
     "duration": 4.612286,
     "end_time": "2022-03-16T06:30:58.438535",
     "exception": false,
     "start_time": "2022-03-16T06:30:53.826249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a57b3",
   "metadata": {
    "papermill": {
     "duration": 0.029584,
     "end_time": "2022-03-16T06:30:58.498989",
     "exception": false,
     "start_time": "2022-03-16T06:30:58.469405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Copy dataset to arrange audio and noise in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b42a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:30:58.564340Z",
     "iopub.status.busy": "2022-03-16T06:30:58.563521Z",
     "iopub.status.idle": "2022-03-16T06:31:39.163634Z",
     "shell.execute_reply": "2022-03-16T06:31:39.163146Z",
     "shell.execute_reply.started": "2022-03-16T04:53:58.825528Z"
    },
    "papermill": {
     "duration": 40.634346,
     "end_time": "2022-03-16T06:31:39.163785",
     "exception": false,
     "start_time": "2022-03-16T06:30:58.529439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r \"../input/speaker-recognition-dataset\" ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce794d",
   "metadata": {
    "papermill": {
     "duration": 0.059375,
     "end_time": "2022-03-16T06:31:39.255871",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.196496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get the data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d75213e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:39.379689Z",
     "iopub.status.busy": "2022-03-16T06:31:39.378881Z",
     "iopub.status.idle": "2022-03-16T06:31:39.382009Z",
     "shell.execute_reply": "2022-03-16T06:31:39.382605Z",
     "shell.execute_reply.started": "2022-03-16T04:56:23.0396Z"
    },
    "papermill": {
     "duration": 0.062787,
     "end_time": "2022-03-16T06:31:39.382799",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.320012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_directory = \"./speaker-recognition-dataset/16000_pcm_speeches\"\n",
    "audio_folder = \"audio\"\n",
    "noise_folder = \"noise\"\n",
    "\n",
    "audio_path = os.path.join(data_directory, audio_folder)\n",
    "noise_path = os.path.join(data_directory, noise_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bc5654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:39.492227Z",
     "iopub.status.busy": "2022-03-16T06:31:39.491381Z",
     "iopub.status.idle": "2022-03-16T06:31:39.498457Z",
     "shell.execute_reply": "2022-03-16T06:31:39.499036Z",
     "shell.execute_reply.started": "2022-03-16T04:56:25.698338Z"
    },
    "papermill": {
     "duration": 0.06724,
     "end_time": "2022-03-16T06:31:39.499246",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.432006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./speaker-recognition-dataset/16000_pcm_speeches/audio'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44ca56",
   "metadata": {
    "papermill": {
     "duration": 0.049484,
     "end_time": "2022-03-16T06:31:39.598907",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.549423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "set all the parameters for training and other purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d596841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:39.705066Z",
     "iopub.status.busy": "2022-03-16T06:31:39.704212Z",
     "iopub.status.idle": "2022-03-16T06:31:39.706442Z",
     "shell.execute_reply": "2022-03-16T06:31:39.705764Z",
     "shell.execute_reply.started": "2022-03-16T04:56:41.399019Z"
    },
    "papermill": {
     "duration": 0.058308,
     "end_time": "2022-03-16T06:31:39.706605",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.648297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_split = 0.1\n",
    "\n",
    "shuffle_seed = 43\n",
    "\n",
    "sample_rate = 16000\n",
    "\n",
    "scale = 0.5\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac44a15",
   "metadata": {
    "papermill": {
     "duration": 0.051687,
     "end_time": "2022-03-16T06:31:39.807414",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.755727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "arrange audio and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa49a502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:39.878677Z",
     "iopub.status.busy": "2022-03-16T06:31:39.877864Z",
     "iopub.status.idle": "2022-03-16T06:31:40.124002Z",
     "shell.execute_reply": "2022-03-16T06:31:40.123458Z",
     "shell.execute_reply.started": "2022-03-16T04:56:46.102133Z"
    },
    "papermill": {
     "duration": 0.283154,
     "end_time": "2022-03-16T06:31:40.124156",
     "exception": false,
     "start_time": "2022-03-16T06:31:39.841002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in os.listdir(data_directory):\n",
    "    if os.path.isdir(os.path.join(data_directory, folder)):\n",
    "        if folder in [audio_folder, noise_folder]:\n",
    "            \n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            \n",
    "            shutil.move(\n",
    "                os.path.join(data_directory, folder),\n",
    "                os.path.join(noise_path, folder),\n",
    "            )\n",
    "        else:\n",
    "            shutil.move(\n",
    "                os.path.join(data_directory, folder),\n",
    "                os.path.join(audio_path, folder),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05349e73",
   "metadata": {
    "papermill": {
     "duration": 0.031374,
     "end_time": "2022-03-16T06:31:40.189656",
     "exception": false,
     "start_time": "2022-03-16T06:31:40.158282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get the list of all noise files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f96fa21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:40.256447Z",
     "iopub.status.busy": "2022-03-16T06:31:40.255738Z",
     "iopub.status.idle": "2022-03-16T06:31:40.258691Z",
     "shell.execute_reply": "2022-03-16T06:31:40.258162Z",
     "shell.execute_reply.started": "2022-03-16T04:57:14.497069Z"
    },
    "papermill": {
     "duration": 0.038716,
     "end_time": "2022-03-16T06:31:40.258814",
     "exception": false,
     "start_time": "2022-03-16T06:31:40.220098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "noise_paths = []\n",
    "for subdir in os.listdir(noise_path):\n",
    "    subdir_path = Path(noise_path) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0968963b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:40.328160Z",
     "iopub.status.busy": "2022-03-16T06:31:40.327346Z",
     "iopub.status.idle": "2022-03-16T06:31:40.330423Z",
     "shell.execute_reply": "2022-03-16T06:31:40.330875Z",
     "shell.execute_reply.started": "2022-03-16T04:57:16.374889Z"
    },
    "papermill": {
     "duration": 0.041601,
     "end_time": "2022-03-16T06:31:40.331038",
     "exception": false,
     "start_time": "2022-03-16T06:31:40.289437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speaker-recognition-dataset/16000_pcm_speeches/noise/other/pink_noise.wav',\n",
       " 'speaker-recognition-dataset/16000_pcm_speeches/noise/other/exercise_bike.wav',\n",
       " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/10convert.com_Audience-Claps_daSG5fwdA7o.wav',\n",
       " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/doing_the_dishes.wav',\n",
       " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/running_tap.wav',\n",
       " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/dude_miaowing.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e7fac5",
   "metadata": {
    "papermill": {
     "duration": 0.03303,
     "end_time": "2022-03-16T06:31:40.399583",
     "exception": false,
     "start_time": "2022-03-16T06:31:40.366553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Split noise into chunks of 16,000 steps each**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a03328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:40.465103Z",
     "iopub.status.busy": "2022-03-16T06:31:40.464382Z",
     "iopub.status.idle": "2022-03-16T06:31:40.466414Z",
     "shell.execute_reply": "2022-03-16T06:31:40.466848Z",
     "shell.execute_reply.started": "2022-03-16T04:57:34.609592Z"
    },
    "papermill": {
     "duration": 0.037222,
     "end_time": "2022-03-16T06:31:40.467009",
     "exception": false,
     "start_time": "2022-03-16T06:31:40.429787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
    "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6bcc87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:40.537211Z",
     "iopub.status.busy": "2022-03-16T06:31:40.536409Z",
     "iopub.status.idle": "2022-03-16T06:31:44.482793Z",
     "shell.execute_reply": "2022-03-16T06:31:44.483480Z",
     "shell.execute_reply.started": "2022-03-16T04:57:38.4688Z"
    },
    "papermill": {
     "duration": 3.984125,
     "end_time": "2022-03-16T06:31:44.483688",
     "exception": false,
     "start_time": "2022-03-16T06:31:40.499563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 06:31:42.000775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:42.094410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:42.095159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:42.097773: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-16 06:31:42.098686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:42.099404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:42.100079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:44.038045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:44.038838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:44.039538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 06:31:44.040150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "os.system(command)\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == sample_rate:\n",
    "        slices = int(sample.shape[0] / sample_rate)\n",
    "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aacc3a",
   "metadata": {
    "papermill": {
     "duration": 0.031204,
     "end_time": "2022-03-16T06:31:44.547120",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.515916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DATASET GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79638f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:44.614957Z",
     "iopub.status.busy": "2022-03-16T06:31:44.614071Z",
     "iopub.status.idle": "2022-03-16T06:31:44.616070Z",
     "shell.execute_reply": "2022-03-16T06:31:44.616465Z",
     "shell.execute_reply.started": "2022-03-16T04:57:51.6888Z"
    },
    "papermill": {
     "duration": 0.038576,
     "end_time": "2022-03-16T06:31:44.616593",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.578017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db00f705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:44.683281Z",
     "iopub.status.busy": "2022-03-16T06:31:44.682464Z",
     "iopub.status.idle": "2022-03-16T06:31:44.685046Z",
     "shell.execute_reply": "2022-03-16T06:31:44.684636Z",
     "shell.execute_reply.started": "2022-03-16T04:57:54.433602Z"
    },
    "papermill": {
     "duration": 0.037429,
     "end_time": "2022-03-16T06:31:44.685167",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.647738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_to_audio(path):\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d5e6c",
   "metadata": {
    "papermill": {
     "duration": 0.030411,
     "end_time": "2022-03-16T06:31:44.751411",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.721000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**add noise to dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ebcbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:44.822787Z",
     "iopub.status.busy": "2022-03-16T06:31:44.821217Z",
     "iopub.status.idle": "2022-03-16T06:31:44.823397Z",
     "shell.execute_reply": "2022-03-16T06:31:44.823801Z",
     "shell.execute_reply.started": "2022-03-16T04:57:57.954149Z"
    },
    "papermill": {
     "duration": 0.041045,
     "end_time": "2022-03-16T06:31:44.823959",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.782914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bee0f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:44.893255Z",
     "iopub.status.busy": "2022-03-16T06:31:44.891662Z",
     "iopub.status.idle": "2022-03-16T06:31:44.893840Z",
     "shell.execute_reply": "2022-03-16T06:31:44.894281Z",
     "shell.execute_reply.started": "2022-03-16T04:58:00.196462Z"
    },
    "papermill": {
     "duration": 0.039407,
     "end_time": "2022-03-16T06:31:44.894419",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.855012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def audio_to_fft(audio):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "367673d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:44.962483Z",
     "iopub.status.busy": "2022-03-16T06:31:44.961911Z",
     "iopub.status.idle": "2022-03-16T06:31:44.989114Z",
     "shell.execute_reply": "2022-03-16T06:31:44.989670Z",
     "shell.execute_reply.started": "2022-03-16T04:58:04.665064Z"
    },
    "papermill": {
     "duration": 0.064635,
     "end_time": "2022-03-16T06:31:44.989862",
     "exception": false,
     "start_time": "2022-03-16T06:31:44.925227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Magaret_Tarcher', 'Julia_Gillard', 'Jens_Stoltenberg', 'Nelson_Mandela', 'Benjamin_Netanyau']\n",
      "Speaker: Magaret_Tarcher\n",
      "Speaker: Julia_Gillard\n",
      "Speaker: Jens_Stoltenberg\n",
      "Speaker: Nelson_Mandela\n",
      "Speaker: Benjamin_Netanyau\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_names = os.listdir(audio_path)\n",
    "print(class_names,)\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Speaker:\",(name))\n",
    "    dir_path = Path(audio_path) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065c7e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:45.060822Z",
     "iopub.status.busy": "2022-03-16T06:31:45.060104Z",
     "iopub.status.idle": "2022-03-16T06:31:45.062774Z",
     "shell.execute_reply": "2022-03-16T06:31:45.062372Z",
     "shell.execute_reply.started": "2022-03-16T04:58:07.804877Z"
    },
    "papermill": {
     "duration": 0.040326,
     "end_time": "2022-03-16T06:31:45.062890",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.022564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shuffle to generate random data\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(audio_paths)\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47e7a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:45.131065Z",
     "iopub.status.busy": "2022-03-16T06:31:45.130315Z",
     "iopub.status.idle": "2022-03-16T06:31:45.132941Z",
     "shell.execute_reply": "2022-03-16T06:31:45.132515Z",
     "shell.execute_reply.started": "2022-03-16T04:58:09.778904Z"
    },
    "papermill": {
     "duration": 0.038932,
     "end_time": "2022-03-16T06:31:45.133058",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.094126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into training and validation\n",
    "num_val_samples = int(valid_split * len(audio_paths))\n",
    "train_audio_paths = audio_paths[:-num_val_samples]\n",
    "train_labels = labels[:-num_val_samples]\n",
    "\n",
    "\n",
    "valid_audio_paths = audio_paths[-num_val_samples:]\n",
    "valid_labels = labels[-num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f94e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:45.214621Z",
     "iopub.status.busy": "2022-03-16T06:31:45.209466Z",
     "iopub.status.idle": "2022-03-16T06:31:45.374768Z",
     "shell.execute_reply": "2022-03-16T06:31:45.375222Z",
     "shell.execute_reply.started": "2022-03-16T04:58:12.721053Z"
    },
    "papermill": {
     "duration": 0.210876,
     "end_time": "2022-03-16T06:31:45.375375",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.164499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a11909",
   "metadata": {
    "papermill": {
     "duration": 0.030813,
     "end_time": "2022-03-16T06:31:45.437469",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.406656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed18061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:45.510612Z",
     "iopub.status.busy": "2022-03-16T06:31:45.509804Z",
     "iopub.status.idle": "2022-03-16T06:31:45.808169Z",
     "shell.execute_reply": "2022-03-16T06:31:45.807667Z",
     "shell.execute_reply.started": "2022-03-16T04:58:19.782275Z"
    },
    "papermill": {
     "duration": 0.338893,
     "end_time": "2022-03-16T06:31:45.808293",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.469400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e266d",
   "metadata": {
    "papermill": {
     "duration": 0.031718,
     "end_time": "2022-03-16T06:31:45.872011",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.840293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f38f4a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:45.939562Z",
     "iopub.status.busy": "2022-03-16T06:31:45.937798Z",
     "iopub.status.idle": "2022-03-16T06:31:46.852758Z",
     "shell.execute_reply": "2022-03-16T06:31:46.851908Z",
     "shell.execute_reply.started": "2022-03-16T04:58:29.334529Z"
    },
    "papermill": {
     "duration": 0.949558,
     "end_time": "2022-03-16T06:31:46.852898",
     "exception": false,
     "start_time": "2022-03-16T06:31:45.903340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860b44bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:46.929745Z",
     "iopub.status.busy": "2022-03-16T06:31:46.929116Z",
     "iopub.status.idle": "2022-03-16T06:31:47.215517Z",
     "shell.execute_reply": "2022-03-16T06:31:47.216074Z",
     "shell.execute_reply.started": "2022-03-16T04:58:38.897812Z"
    },
    "papermill": {
     "duration": 0.33155,
     "end_time": "2022-03-16T06:31:47.216236",
     "exception": false,
     "start_time": "2022-03-16T06:31:46.884686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 8000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 8000, 128)    512         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8000, 128)    0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 8000, 128)    49280       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8000, 128)    0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 8000, 128)    49280       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 8000, 128)    256         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8000, 128)    0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8000, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 4000, 128)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 1333, 128)    0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 170624)       0           average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          43680000    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 5)            645         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,812,869\n",
      "Trainable params: 43,812,869\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n",
    "    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n",
    "    \n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n",
    "    \n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(inputs, 32, 2)\n",
    "    x = residual_block(inputs, 64, 3)\n",
    "    x = residual_block(inputs, 128, 3)\n",
    "    x = residual_block(inputs, 128, 3)\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n",
    "    \n",
    "    return keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model = build_model((sample_rate // 2, 1), len(class_names))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81558457",
   "metadata": {
    "papermill": {
     "duration": 0.031822,
     "end_time": "2022-03-16T06:31:47.280145",
     "exception": false,
     "start_time": "2022-03-16T06:31:47.248323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad872c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T06:31:47.349705Z",
     "iopub.status.busy": "2022-03-16T06:31:47.349038Z",
     "iopub.status.idle": "2022-03-16T07:10:53.671296Z",
     "shell.execute_reply": "2022-03-16T07:10:53.672393Z",
     "shell.execute_reply.started": "2022-03-15T13:23:08.000948Z"
    },
    "papermill": {
     "duration": 2346.360222,
     "end_time": "2022-03-16T07:10:53.672615",
     "exception": false,
     "start_time": "2022-03-16T06:31:47.312393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 06:31:47.413606: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 06:31:51.823015: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 75s 1s/step - loss: 18.5610 - accuracy: 0.5433 - val_loss: 0.2614 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.2887 - accuracy: 0.9008 - val_loss: 0.1232 - val_accuracy: 0.9627\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.1416 - accuracy: 0.9474 - val_loss: 0.1501 - val_accuracy: 0.9347\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.1588 - accuracy: 0.9425 - val_loss: 0.1141 - val_accuracy: 0.9587\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.1820 - accuracy: 0.9332 - val_loss: 0.0823 - val_accuracy: 0.9720\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0991 - accuracy: 0.9618 - val_loss: 0.0603 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0666 - accuracy: 0.9767 - val_loss: 0.0577 - val_accuracy: 0.9787\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0574 - accuracy: 0.9796 - val_loss: 0.0537 - val_accuracy: 0.9800\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 0.0404 - val_accuracy: 0.9893\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0523 - accuracy: 0.9806 - val_loss: 0.0747 - val_accuracy: 0.9747\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0428 - accuracy: 0.9846 - val_loss: 0.0793 - val_accuracy: 0.9707\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0401 - accuracy: 0.9847 - val_loss: 0.0822 - val_accuracy: 0.9747\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0264 - val_accuracy: 0.9907\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.0393 - val_accuracy: 0.9880\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.0499 - val_accuracy: 0.9880\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0584 - val_accuracy: 0.9827\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.0287 - val_accuracy: 0.9920\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0885 - val_accuracy: 0.9693\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.0285 - val_accuracy: 0.9947\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.0241 - val_accuracy: 0.9947\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.0316 - val_accuracy: 0.9933\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.0488 - val_accuracy: 0.9853\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0317 - val_accuracy: 0.9920\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.1043 - val_accuracy: 0.9773\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.0489 - val_accuracy: 0.9907\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.0365 - val_accuracy: 0.9907\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0410 - val_accuracy: 0.9920\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0447 - val_accuracy: 0.9867\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 68s 1s/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0306 - val_accuracy: 0.9933\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0289 - val_accuracy: 0.9920\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f20ae9",
   "metadata": {
    "papermill": {
     "duration": 0.569455,
     "end_time": "2022-03-16T07:10:54.855508",
     "exception": false,
     "start_time": "2022-03-16T07:10:54.286053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86a7726e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T07:10:55.990990Z",
     "iopub.status.busy": "2022-03-16T07:10:55.990099Z",
     "iopub.status.idle": "2022-03-16T07:11:02.814039Z",
     "shell.execute_reply": "2022-03-16T07:11:02.815492Z",
     "shell.execute_reply.started": "2022-03-15T14:03:59.388539Z"
    },
    "papermill": {
     "duration": 7.401613,
     "end_time": "2022-03-16T07:11:02.815707",
     "exception": false,
     "start_time": "2022-03-16T07:10:55.414094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 7s 270ms/step - loss: 0.0241 - accuracy: 0.9947\n",
      "Accuracy of model: [0.024073410779237747, 0.9946666955947876]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model:\",model.evaluate(valid_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5155be7",
   "metadata": {
    "papermill": {
     "duration": 0.56052,
     "end_time": "2022-03-16T07:11:03.992327",
     "exception": false,
     "start_time": "2022-03-16T07:11:03.431807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f9e4102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T07:11:05.412860Z",
     "iopub.status.busy": "2022-03-16T07:11:05.412296Z",
     "iopub.status.idle": "2022-03-16T07:11:07.332973Z",
     "shell.execute_reply": "2022-03-16T07:11:07.333381Z",
     "shell.execute_reply.started": "2022-03-15T14:06:22.041545Z"
    },
    "papermill": {
     "duration": 2.505645,
     "end_time": "2022-03-16T07:11:07.333533",
     "exception": false,
     "start_time": "2022-03-16T07:11:04.827888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n",
      "Welcome\n",
      "The speaker is Julia_Gillard\n",
      "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
      "Welcome\n",
      "The speaker is Nelson_Mandela\n",
      "Speaker:\u001b[92m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[92m Benjamin_Netanyau\u001b[0m\n",
      "Welcome\n",
      "The speaker is Benjamin_Netanyau\n",
      "Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n",
      "Welcome\n",
      "The speaker is Julia_Gillard\n",
      "Speaker:\u001b[92m Jens_Stoltenberg\u001b[0m\tPredicted:\u001b[92m Jens_Stoltenberg\u001b[0m\n",
      "Welcome\n",
      "The speaker is Jens_Stoltenberg\n",
      "Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n",
      "Welcome\n",
      "The speaker is Magaret_Tarcher\n",
      "Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n",
      "Welcome\n",
      "The speaker is Julia_Gillard\n",
      "Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n",
      "Welcome\n",
      "The speaker is Julia_Gillard\n",
      "Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n",
      "Welcome\n",
      "The speaker is Magaret_Tarcher\n",
      "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
      "Welcome\n",
      "The speaker is Nelson_Mandela\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_TO_DISPLAY = 10\n",
    "\n",
    "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "test_ds = test_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
    "\n",
    "for audios, labels in test_ds.take(1):\n",
    "    ffts = audio_to_fft(audios)\n",
    "    y_pred = model.predict(ffts)\n",
    "    rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n",
    "    audios = audios.numpy()[rnd, :, :]\n",
    "    labels = labels.numpy()[rnd]\n",
    "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(SAMPLES_TO_DISPLAY):\n",
    "        print(\n",
    "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
    "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
    "                class_names[labels[index]],\n",
    "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
    "                class_names[y_pred[index]],\n",
    "            )\n",
    "        )\n",
    "        if labels[index] ==y_pred[index]:\n",
    "            print(\"Welcome\")\n",
    "        else:\n",
    "            print(\"Sorry\")\n",
    "        print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d18b6",
   "metadata": {
    "papermill": {
     "duration": 0.568,
     "end_time": "2022-03-16T07:11:08.526823",
     "exception": false,
     "start_time": "2022-03-16T07:11:07.958823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Predcit the speaker from the test dataset for real time pred.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2af9fbb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T07:11:09.672807Z",
     "iopub.status.busy": "2022-03-16T07:11:09.671878Z",
     "iopub.status.idle": "2022-03-16T07:11:09.673774Z",
     "shell.execute_reply": "2022-03-16T07:11:09.674234Z",
     "shell.execute_reply.started": "2022-03-15T14:11:36.520774Z"
    },
    "papermill": {
     "duration": 0.578347,
     "end_time": "2022-03-16T07:11:09.674399",
     "exception": false,
     "start_time": "2022-03-16T07:11:09.096052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def paths_to_dataset(audio_paths):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    return tf.data.Dataset.zip((path_ds))\n",
    "\n",
    "def predict(path, labels):\n",
    "    test = paths_and_labels_to_dataset(path, labels)\n",
    "\n",
    "\n",
    "    test = test.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    "    )\n",
    "    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "    test = test.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
    "\n",
    "    for audios, labels in test.take(1):\n",
    "        ffts = audio_to_fft(audios)\n",
    "        y_pred = model.predict(ffts)\n",
    "        rnd = np.random.randint(0, 1, 1)\n",
    "        audios = audios.numpy()[rnd, :]\n",
    "        labels = labels.numpy()[rnd]\n",
    "        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(1):\n",
    "            print(\n",
    "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
    "            \"[92m\",y_pred[index],\n",
    "                \"[92m\", y_pred[index]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print(\"Speaker Predicted:\",class_names[y_pred[index]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1a00c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T07:11:10.845070Z",
     "iopub.status.busy": "2022-03-16T07:11:10.844491Z",
     "iopub.status.idle": "2022-03-16T07:11:11.096451Z",
     "shell.execute_reply": "2022-03-16T07:11:11.096868Z",
     "shell.execute_reply.started": "2022-03-15T14:11:45.068176Z"
    },
    "papermill": {
     "duration": 0.833405,
     "end_time": "2022-03-16T07:11:11.097046",
     "exception": false,
     "start_time": "2022-03-16T07:11:10.263641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker:\u001b[92m 2\u001b[0m\tPredicted:\u001b[92m 2\u001b[0m\n",
      "Speaker Predicted: Jens_Stoltenberg\n"
     ]
    }
   ],
   "source": [
    "path = [\"../input/speaker-recognition-dataset/16000_pcm_speeches/Jens_Stoltenberg/1013.wav\"]\n",
    "labels = [\"unknown\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71ec08",
   "metadata": {
    "papermill": {
     "duration": 0.568847,
     "end_time": "2022-03-16T07:11:12.258298",
     "exception": false,
     "start_time": "2022-03-16T07:11:11.689451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2430.942457,
   "end_time": "2022-03-16T07:11:16.570111",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-16T06:30:45.627654",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
